# :balloon: Papers to Read

This repository contains a curated list of research papers that either I already read 
or I plan to read. Additionally, some of them come along with a personal repository I created so 
as to have a better understanding of the papers, explaining complex ideas with my own words, and 
simplifying hard-to-understand concepts. Also, some of those contain an implementation in either
TensorFlow/Keras, PyTorch, MXNet or JAX.

:warning: __Disclaimer__. This is a personal repository, so what may be useful or easy to understand to me
may be complex to you, so don't take the contents listed here as a must-follow guide. This
is just the way I share what I usually do while reading/implementing research papers.

:man_teacher: __Credits__. Obviously the credits go to the original authors of the papers, but I would like
also to thank [Ross Wightman](https://github.com/rwightman), [Phil Wang](https://github.com/lucidrains), and 
[Yannic Kilcher](https://youtube.com/c/yannickilcher) for the inspiration to start sharing how do I read and 
implement ML/DL research papers. Also as a personal recommendation go check their socials, as all of 
them create awesome content that you should keep an eye on if interested in ML/DL.

---

## [`understanding-resnet`](https://github.com/alvarobartt/understanding-resnet)

| Research Paper | URL |
|----------------|-----|
| _Deep Residual Learning for Image Recognition (ResNet)_ | [![arXiv](https://img.shields.io/badge/arXiv-1512.03385-b31b1b.svg?style=flat)](https://arxiv.org/abs/1512.03385)
| _Bag of Tricks for Image Classification with Convolutional Neural Networks_ | [![arXiv](https://img.shields.io/badge/arXiv-1812.01187-b31b1b.svg?style=flat)](https://arxiv.org/abs/1812.01187)
| _Identity Mappings in Deep Residual Networks (ResNet v2)_ | [![arXiv](https://img.shields.io/badge/arXiv-1603.05027-b31b1b.svg?style=flat)](https://arxiv.org/abs/1603.05027)

__TL;DR__ In Residual Learning the layers are reformulated as learning residual functions with
reference to the layer inputs. These networks are easier to optimize, and can gain accuracy
from considerably increased depth. Along this repository not just an explanation is provided
but also the implementation of the original ResNet architecture written in PyTorch. 
Additionally, here you will also find some ResNets trained with CIFAR10, as proposed by the
authors; which are some of the smallest ResNets described in the original paper. And, also some
ported weights for the bigger ResNets trained with ImageNet.

---

## [`understanding-efficientnet`](https://github.com/alvarobartt/understanding-efficientnet) - Not ready yet!

| Research Paper | URL |
|----------------|-----|
| _EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks_ | [![arXiv](https://img.shields.io/badge/arXiv-1905.11946-b31b1b.svg?style=flat)](https://arxiv.org/abs/1905.11946)
| _EfficientNetV2: Smaller Models and Faster Training_ | [![arXiv](https://img.shields.io/badge/arXiv-2104.00298-b31b1b.svg?style=flat)](https://arxiv.org/abs/2104.00298)

---

## [`understanding-vgg`](https://github.com/alvarobartt/understanding-vgg) - Not ready yet!

| Research Paper | URL |
|----------------|-----|
| _Very Deep Convolutional Networks for Large-Scale Image Recognition_ | [![arXiv](https://img.shields.io/badge/arXiv-1409.1556-b31b1b.svg?style=flat)](https://arxiv.org/abs/1409.1556)

---

## [`understanding-yolo`](https://github.com/alvarobartt/understanding-yolo) - Not ready yet!

| Research Paper | URL |
|----------------|-----|
| _You Only Look Once: Unified, Real-Time Object Detection_ | [![arXiv](https://img.shields.io/badge/arXiv-1506.02640-b31b1b.svg?style=flat)](https://arxiv.org/abs/1506.02640)
| _YOLO Nano: a Highly Compact You Only Look Once Convolutional Neural Network for Object Detection_ | [![arXiv](https://img.shields.io/badge/arXiv-1910.01271-b31b1b.svg?style=flat)](https://arxiv.org/abs/1910.01271)
| _YOLO9000: Better, Faster, Stronger (YOLOv2)_ | [![arXiv](https://img.shields.io/badge/arXiv-1612.08242-b31b1b.svg?style=flat)](https://arxiv.org/abs/1612.08242)
| _YOLOv3: An Incremental Improvement_ | [![arXiv](https://img.shields.io/badge/arXiv-1804.02767-b31b1b.svg?style=flat)](https://arxiv.org/abs/1804.02767)
| _YOLOv4: Optimal Speed and Accuracy of Object Detection_ | [![arXiv](https://img.shields.io/badge/arXiv-2004.10934-b31b1b.svg?style=flat)](https://arxiv.org/abs/2004.10934)

---

## :crystal_ball: Future Papers to Read

| Research Paper | URL |
|----------------|-----|
| _High-Performance Large-Scale Image Recognition Without Normalization_ | [![arXiv](https://img.shields.io/badge/arXiv-2102.06171-b31b1b.svg?style=flat)](https://arxiv.org/abs/2102.06171)
| _Fully Convolutional Networks for Image Segmentation_ | [![arXiv](https://img.shields.io/badge/arXiv-1411.4038-b31b1b.svg?style=flat)](https://arxiv.org/abs/1411.4038)
| _DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs_ | [![arXiv](https://img.shields.io/badge/arXiv-1606.00915-b31b1b.svg?style=flat)](https://arxiv.org/abs/1606.00915)
| _SSD: Single Shot MultiBox Detector_ | [![arXiv](https://img.shields.io/badge/arXiv-1512.02325-b31b1b.svg?style=flat)](https://arxiv.org/abs/1512.02325)
| _Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks_ | [![arXiv](https://img.shields.io/badge/arXiv-1506.01497-b31b1b.svg?style=flat)](https://arxiv.org/abs/1506.01497)
| _Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift_ | [![arXiv](https://img.shields.io/badge/arXiv-1502.03167-b31b1b.svg?style=flat)](https://arxiv.org/abs/1502.03167)
| _SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size_ | [![arXiv](https://img.shields.io/badge/arXiv-1602.07360-b31b1b.svg?style=flat)](https://arxiv.org/abs/1602.07360)
| _FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction_ | [![arXiv](https://img.shields.io/badge/arXiv-1901.03495-b31b1b.svg?style=flat)](https://arxiv.org/abs/1901.03495)
